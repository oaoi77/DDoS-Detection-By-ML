{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    \"df_fw1\": pd.read_csv(\"extracted_flow_features_fw1.csv\"),\n",
    "    \"df_fw2\": pd.read_csv(\"extracted_flow_features_fw2.csv\"),\n",
    "    \"df_fw3\": pd.read_csv(\"extracted_flow_features_fw3.csv\"),\n",
    "    \"df_fw4\": pd.read_csv(\"extracted_flow_features_fw4.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_fw0\n",
      "Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'label'], dtype='object')\n",
      "df_fw1\n",
      "Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'label'], dtype='object')\n",
      "df_fw2\n",
      "Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'label'], dtype='object')\n",
      "df_fw3\n",
      "Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.keys())):\n",
    "    print(\"df_fw\" + str(i))\n",
    "    print(df[list(df.keys())[i]].select_dtypes(include=\"object\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Features: {'Total Length', 'Total Packets', 'Flow IAT Max', 'RST Flag Count', 'Duration', 'Flow IAT Total', 'Packet Length Min', 'Flow IAT Min', 'Active Std', 'Flow IAT Std', 'Active Mean', 'Flow IAT Mean', 'Packet Length Max'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "validColumn = {}\n",
    "for i in range(len(df.keys())):\n",
    "    # print(\"df_fw\" + str(i))\n",
    "    encoderTarget = LabelEncoder()\n",
    "    testCorrDF = df[list(df.keys())[i]].copy()\n",
    "    testCorrDF['label'] = encoderTarget.fit_transform(testCorrDF['label'])\n",
    "    labelCorr = testCorrDF.select_dtypes(exclude=\"object\").corr()['label']\n",
    "    # print(labelCorr[labelCorr < 0.9])\n",
    "    validColumn[f\"{list(df.keys())[i]}\"] = list(labelCorr[labelCorr < 0.9].index)\n",
    "\n",
    "commonFeatures = set(validColumn[\"df_fw1\"]).intersection(validColumn['df_fw2'], validColumn['df_fw3'], validColumn['df_fw4'])\n",
    "print(f\"Common Features: {commonFeatures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total Length',\n",
       " 'Total Packets',\n",
       " 'Flow IAT Max',\n",
       " 'RST Flag Count',\n",
       " 'Duration',\n",
       " 'Flow IAT Total',\n",
       " 'Packet Length Min',\n",
       " 'Flow IAT Min',\n",
       " 'Active Std',\n",
       " 'Flow IAT Std',\n",
       " 'Active Mean',\n",
       " 'Flow IAT Mean',\n",
       " 'Packet Length Max']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonFeatures = list(commonFeatures)\n",
    "commonFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[88], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mCustomEncoder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CustomLabelEncoder\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m----> 5\u001B[0m input_data \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      6\u001B[0m output_data \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      8\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(input_data, output_data, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "# Within the same dataset, then divide into train and test\n",
    "from research.Internal.CustomEncoder import CustomLabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_data = df.drop(columns= ['label'])\n",
    "output_data = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.2, shuffle= True, random_state=42)\n",
    "\n",
    "\n",
    "columns_toEncode = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'label']\n",
    "\n",
    "for col in columns_toEncode:\n",
    "    encoder = CustomLabelEncoder()\n",
    "    if col in input_data.columns:\n",
    "        X_train[col] = encoder.fit_transform(X_train[col])\n",
    "        X_test[col] = encoder.transform(X_test[col])\n",
    "    else:\n",
    "        y_train = encoder.fit_transform(y_train)\n",
    "        y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With two different dataset\n",
    "from research.Internal.CustomEncoder import CustomLabelEncoder\n",
    "\n",
    "# X_train = df[\"df_fw1\"].drop(columns=['label'])\n",
    "# X_test = df[\"df_fw3\"].drop(columns=['label'])\n",
    "\n",
    "X_train = df[\"df_fw1\"].drop(columns=['label'])[commonFeatures]\n",
    "X_test = df[\"df_fw3\"].drop(columns=['label'])[commonFeatures]\n",
    "\n",
    "y_train = df[\"df_fw1\"]['label']\n",
    "y_test = df[\"df_fw3\"]['label']\n",
    "\n",
    "# Labling Data\n",
    "\n",
    "# columns_toEncode = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Protocol', 'label']\n",
    "# XColumn = [col for col in columns_toEncode if col != 'label']\n",
    "# yColumn = [col for col in columns_toEncode if col not in XColumn]\n",
    "\n",
    "# for col in columns_toEncode:\n",
    "#     encoder = CustomLabelEncoder()\n",
    "#     if col in XColumn:\n",
    "#         X_train[col] = encoder.fit_transform(X_train[col])\n",
    "#         X_test[col] = encoder.transform(X_test[col])\n",
    "#     if col in yColumn:\n",
    "#         y_train = encoder.fit_transform(y_train)\n",
    "#         y_test = encoder.transform(y_test)\n",
    "\n",
    "encoder = CustomLabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ATTACKER\n",
      "1 : BENIGN\n"
     ]
    }
   ],
   "source": [
    "for i, value in enumerate(encoder.encoder.classes_):\n",
    "    print(f\"{i} : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[33708     0]\n",
      " [    0  1659]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33708\n",
      "           1       1.00      1.00      1.00      1659\n",
      "\n",
      "    accuracy                           1.00     35367\n",
      "   macro avg       1.00      1.00      1.00     35367\n",
      "weighted avg       1.00      1.00      1.00     35367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n",
    "print(\"Classification Report:\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[   23 33685]\n",
      " [    0  1659]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     33708\n",
      "           1       0.05      1.00      0.09      1659\n",
      "\n",
      "    accuracy                           0.05     35367\n",
      "   macro avg       0.52      0.50      0.05     35367\n",
      "weighted avg       0.96      0.05      0.01     35367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n",
    "print(\"Classification Report:\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[33708     0]\n",
      " [   51  1608]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33708\n",
      "           1       1.00      0.97      0.98      1659\n",
      "\n",
      "    accuracy                           1.00     35367\n",
      "   macro avg       1.00      0.98      0.99     35367\n",
      "weighted avg       1.00      1.00      1.00     35367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\", conf_matrix)\n",
    "print(\"Classification Report:\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
